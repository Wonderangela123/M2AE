# M2AE

# M2AE is a predictive framework with multi-view data. The model learns view-specific representation via attentive encoders (AEs) and integrates multi-view data using the View Correlation Discovery Network (VCDN). For each view, an attentive encoder was employed to leverage both view-specific features and their corresponding sample similarity network, employing Multi-Layer Perceptrons (MLP) in a sequential manner for learning view-specific representations. A cross-view discovery tensor was calculated using the latent representations from all types of views. A VCDN was then trained with the cross-view discovery tensor to produce the final predictions. M2AE is an end-to-end model, where both view-specific attentive encoders and VCDN are trained jointly.
